{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fe60a1",
   "metadata": {},
   "source": [
    "In this notebook, we explore the ODMSemantic3D dataset, and how we can preprocess it for use in training a semantic segmentation model.\n",
    "\n",
    "The following are some of the labels of the dataset from the GitHub Repo:\n",
    "\n",
    "\n",
    "ground\t- 2\t\n",
    "\n",
    "low_vegetation\t- 3\t\n",
    "\n",
    "building -\t6\n",
    "\n",
    "human_made_object -\t64\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ef5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets/odm_data_waterbury-roads_2.npz\")\n",
    "points = data['pointclouds']   # shape: (num_samples, num_points, 3)\n",
    "labels = data['labels']   # shape: (num_samples, num_points)\n",
    "\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c2207",
   "metadata": {},
   "source": [
    "Now we will plot one of the datasets from the .npz files that were produced from the dataset.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd873f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Get the first sample\n",
    "pc = points[0]  # shape: (N, 3)\n",
    "lbl = labels[0]  # shape: (N,)\n",
    "\n",
    "# Use entire dataset\n",
    "pc_full = pc\n",
    "lbl_full = lbl\n",
    "\n",
    "# Calculate full ranges for X and Y\n",
    "x_min, x_max = pc_full[:, 0].min(), pc_full[:, 0].max()\n",
    "y_min, y_max = pc_full[:, 1].min(), pc_full[:, 1].max()\n",
    "\n",
    "print(f\"Total points: {len(pc_full):,}\")\n",
    "print(f\"X range: [{x_min:.2f}, {x_max:.2f}]\")\n",
    "print(f\"Y range: [{y_min:.2f}, {y_max:.2f}]\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Get unique labels and assign colors\n",
    "unique_labels = np.unique(lbl_full)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Plot points colored by label (sample if too many points for performance)\n",
    "# For very large datasets, we can sample points for visualization\n",
    "max_points_to_plot = 10000000  # Adjust based on performance needs\n",
    "if len(pc_full) > max_points_to_plot:\n",
    "    # Randomly sample points\n",
    "    indices = np.random.choice(len(pc_full), max_points_to_plot, replace=False)\n",
    "    pc_plot = pc_full[indices]\n",
    "    lbl_plot = lbl_full[indices]\n",
    "    print(f\"Sampling {max_points_to_plot:,} points for visualization (out of {len(pc_full):,} total)\")\n",
    "else:\n",
    "    pc_plot = pc_full\n",
    "    lbl_plot = lbl_full\n",
    "\n",
    "# Plot points colored by their labels\n",
    "for label in unique_labels:\n",
    "    mask = lbl_plot == label\n",
    "    if np.any(mask):\n",
    "        label_points = pc_plot[mask]\n",
    "        ax.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                  c=[color_map[label]], s=10, alpha=0.6, \n",
    "                  label=f'Label {label}', edgecolors='none')\n",
    "\n",
    "# Set axis limits to show entire dataset\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Point Cloud: Entire Dataset - Points Colored by Labels')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=16)\n",
    "ax.grid(True, alpha=0.)\n",
    "\n",
    "# Use auto aspect instead of equal to avoid dimension issues\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781b507",
   "metadata": {},
   "source": [
    "So looks to me like some houses are present next to those roads (as labelled)\n",
    "\n",
    "Let's examine the other datasets next, and then we will also want to explore the local gradients to see if changes in Z will be picked up by the model - or if they are not steep/step changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e2be3",
   "metadata": {},
   "source": [
    "Let's examine the remaining datasets for their characeristics and data cleanliness,then we will plot them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the datasets directory\n",
    "datasets_dir = Path(\"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets\")\n",
    "npz_files = sorted(datasets_dir.glob(\"*.npz\"))\n",
    "\n",
    "results = []\n",
    "\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        data = np.load(npz_file)\n",
    "        \n",
    "        # Load pointclouds and labels\n",
    "        pointclouds = data['pointclouds'] if 'pointclouds' in data else data.get('points', None)\n",
    "        labels = data.get('labels', None)\n",
    "        \n",
    "        if pointclouds is None:\n",
    "            continue\n",
    "        \n",
    "        num_samples = pointclouds.shape[0]\n",
    "        total_points = pointclouds.shape[0] * pointclouds.shape[1] if len(pointclouds.shape) > 1 else pointclouds.shape[0]\n",
    "        \n",
    "        # Check for NaNs and collect labels\n",
    "        has_nans_points = False\n",
    "        has_nans_labels = False\n",
    "        all_labels = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            pc = pointclouds[i]\n",
    "            lbl = labels[i] if labels is not None else None\n",
    "            \n",
    "            if np.isnan(pc).any():\n",
    "                has_nans_points = True\n",
    "            \n",
    "            if lbl is not None:\n",
    "                if np.isnan(lbl).any():\n",
    "                    has_nans_labels = True\n",
    "                all_labels.extend(np.unique(lbl).tolist())\n",
    "        \n",
    "        unique_labels = sorted(set(all_labels)) if labels is not None else []\n",
    "        \n",
    "        results.append({\n",
    "            'File': npz_file.name,\n",
    "            'Samples': num_samples,\n",
    "            'Shape': str(pointclouds.shape),\n",
    "            'Labels': len(unique_labels),\n",
    "            'Label Values': str(unique_labels),\n",
    "            'NaN Points': '⚠️' if has_nans_points else '✓',\n",
    "            'NaN Labels': '⚠️' if has_nans_labels else ('✓' if labels is not None else 'N/A'),\n",
    "            'Total Points': total_points\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            'File': npz_file.name,\n",
    "            'Samples': 'ERROR',\n",
    "            'Shape': 'ERROR',\n",
    "            'Labels': 'ERROR',\n",
    "            'Label Values': 'ERROR',\n",
    "            'NaN Points': 'ERROR',\n",
    "            'NaN Labels': 'ERROR',\n",
    "            'Total Points': 'ERROR'\n",
    "        })\n",
    "\n",
    "# Print summary table\n",
    "print(f\"{'File':<45} {'Samples':<10} {'Shape':<25} {'Labels':<8} {'NaN P':<8} {'NaN L':<8} {'Total Points':<15}\")\n",
    "print(\"-\" * 130)\n",
    "\n",
    "for r in results:\n",
    "    total_pts = f\"{r['Total Points']:,}\" if isinstance(r['Total Points'], int) else str(r['Total Points'])\n",
    "    print(f\"{r['File']:<45} {str(r['Samples']):<10} {r['Shape']:<25} {str(r['Labels']):<8} {r['NaN Points']:<8} {r['NaN Labels']:<8} {total_pts:<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 130)\n",
    "print(\"Label Values by File:\")\n",
    "print(\"=\" * 130)\n",
    "for r in results:\n",
    "    if r['Label Values'] not in ['N/A', 'ERROR']:\n",
    "        print(f\"{r['File']}: {r['Label Values']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc77ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Define the datasets directory\n",
    "datasets_dir = Path(\"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets\")\n",
    "npz_files = sorted(datasets_dir.glob(\"*.npz\"))\n",
    "\n",
    "# Configuration for performance\n",
    "max_points_for_gradient = 100000  # Lower for faster processing\n",
    "max_points_to_plot = 100000  # Lower number of points for visualization\n",
    "grid_resolution = 150  # Lower resolution for faster gradient computation\n",
    "point_size = 4  # Point size for scatter plots (modify this to change point size)\n",
    "\n",
    "# First pass: Collect all unique labels across all datasets\n",
    "all_unique_labels = set()\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        data = np.load(npz_file)\n",
    "        labels = data.get('labels', None)\n",
    "        if labels is not None:\n",
    "            for sample_labels in labels:\n",
    "                all_unique_labels.update(np.unique(sample_labels))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Create consistent color map for all labels\n",
    "all_unique_labels = sorted(all_unique_labels)\n",
    "num_labels = len(all_unique_labels)\n",
    "# Use tab20 colormap which has 20 distinct colors, extend with Set3 if needed\n",
    "if num_labels <= 20:\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, num_labels))\n",
    "else:\n",
    "    # For more than 20 labels, use Set3 which has more colors\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, num_labels))\n",
    "consistent_color_map = {label: colors[i] for i, label in enumerate(all_unique_labels)}\n",
    "\n",
    "# Second pass: Visualize all datasets with consistent colors\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        # Load the .npz file\n",
    "        data = np.load(npz_file)\n",
    "        \n",
    "        # Load pointclouds and labels\n",
    "        pointclouds = data['pointclouds'] if 'pointclouds' in data else data.get('points', None)\n",
    "        labels = data.get('labels', None)\n",
    "        \n",
    "        if pointclouds is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the first sample\n",
    "        pc_full = pointclouds[0]\n",
    "        lbl_full = labels[0] if labels is not None else None\n",
    "        \n",
    "        # Sample points for gradient computation\n",
    "        if len(pc_full) > max_points_for_gradient:\n",
    "            indices = np.random.choice(len(pc_full), max_points_for_gradient, replace=False)\n",
    "            pc_grad = pc_full[indices]\n",
    "            lbl_grad = lbl_full[indices] if lbl_full is not None else None\n",
    "        else:\n",
    "            pc_grad = pc_full\n",
    "            lbl_grad = lbl_full\n",
    "        \n",
    "        # Extract coordinates for gradient computation\n",
    "        x = pc_grad[:, 0]\n",
    "        y = pc_grad[:, 1]\n",
    "        z = pc_grad[:, 2]\n",
    "        \n",
    "        # Calculate ranges\n",
    "        x_min, x_max = x.min(), x.max()\n",
    "        y_min, y_max = y.min(), y.max()\n",
    "        \n",
    "        # Create a regular grid for gradient computation\n",
    "        xi = np.linspace(x.min(), x.max(), grid_resolution)\n",
    "        yi = np.linspace(y.min(), y.max(), grid_resolution)\n",
    "        xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "        \n",
    "        # Interpolate Z values onto the grid\n",
    "        zi_grid = griddata((x, y), z, (xi_grid, yi_grid), method='linear', fill_value=np.nan)\n",
    "        \n",
    "        # Compute gradient on the grid\n",
    "        dz_dx = np.gradient(zi_grid, axis=1)\n",
    "        dz_dy = np.gradient(zi_grid, axis=0)\n",
    "        \n",
    "        # Compute gradient magnitude (steepness)\n",
    "        gradient_magnitude = np.sqrt(dz_dx**2 + dz_dy**2)\n",
    "        \n",
    "        # Interpolate gradient magnitude back to original point locations\n",
    "        gradient_at_points = griddata(\n",
    "            (xi_grid.flatten(), yi_grid.flatten()), \n",
    "            gradient_magnitude.flatten(), \n",
    "            (x, y), \n",
    "            method='linear', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Handle any NaN values\n",
    "        gradient_at_points = np.nan_to_num(gradient_at_points, nan=0.0)\n",
    "        \n",
    "        # Sample points for visualization\n",
    "        if len(pc_grad) > max_points_to_plot:\n",
    "            plot_indices = np.random.choice(len(pc_grad), max_points_to_plot, replace=False)\n",
    "            pc_plot = pc_grad[plot_indices]\n",
    "            lbl_plot = lbl_grad[plot_indices] if lbl_grad is not None else None\n",
    "            grad_plot = gradient_at_points[plot_indices]\n",
    "        else:\n",
    "            pc_plot = pc_grad\n",
    "            lbl_plot = lbl_grad\n",
    "            grad_plot = gradient_at_points\n",
    "        \n",
    "        # Create figure with two subplots side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "        \n",
    "        # ===== LEFT PLOT: Points colored by labels =====\n",
    "        if lbl_plot is not None:\n",
    "            unique_labels = np.unique(lbl_plot)\n",
    "            \n",
    "            for label in unique_labels:\n",
    "                mask = lbl_plot == label\n",
    "                if np.any(mask):\n",
    "                    label_points = pc_plot[mask]\n",
    "                    # Use consistent color map\n",
    "                    color = consistent_color_map.get(label, 'gray')\n",
    "                    ax1.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                               c=[color], s=point_size, alpha=0.6, \n",
    "                               edgecolors='none')\n",
    "        else:\n",
    "            # If no labels, just plot points in gray\n",
    "            ax1.scatter(pc_plot[:, 0], pc_plot[:, 1], \n",
    "                       c='gray', s=point_size, alpha=0.6, edgecolors='none')\n",
    "            ax1.text(0.5, 0.5, 'No labels available', \n",
    "                    transform=ax1.transAxes, ha='center', va='center', fontsize=14)\n",
    "        \n",
    "        ax1.set_xlim(x_min, x_max)\n",
    "        ax1.set_ylim(y_min, y_max)\n",
    "        ax1.set_xlabel('X Coordinate', fontsize=12)\n",
    "        ax1.set_ylabel('Y Coordinate', fontsize=12)\n",
    "        ax1.set_title(f'{npz_file.name}\\nPoints Colored by Labels', fontsize=14)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_aspect('auto')\n",
    "        \n",
    "        # ===== RIGHT PLOT: Points colored by gradient =====\n",
    "        scatter = ax2.scatter(pc_plot[:, 0], pc_plot[:, 1], \n",
    "                             c=grad_plot, s=point_size, alpha=0.6, \n",
    "                             cmap='viridis', edgecolors='none')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Gradient Magnitude (Steepness)', fontsize=12)\n",
    "        \n",
    "        ax2.set_xlim(x_min, x_max)\n",
    "        ax2.set_ylim(y_min, y_max)\n",
    "        ax2.set_xlabel('X Coordinate', fontsize=12)\n",
    "        ax2.set_ylabel('Y Coordinate', fontsize=12)\n",
    "        ax2.set_title(f'{npz_file.name}\\nPoints Colored by Local Gradient', fontsize=14)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_aspect('auto')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR processing {npz_file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Create a large legend figure at the end\n",
    "fig_legend = plt.figure(figsize=(12, 8))\n",
    "ax_legend = fig_legend.add_subplot(111)\n",
    "ax_legend.axis('off')\n",
    "\n",
    "# Create legend entries for all labels\n",
    "legend_elements = []\n",
    "for label in all_unique_labels:\n",
    "    color = consistent_color_map[label]\n",
    "    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                      markerfacecolor=color, markersize=20, \n",
    "                                      label=f'Label {label}'))\n",
    "\n",
    "# Create the legend\n",
    "legend = ax_legend.legend(handles=legend_elements, loc='center', \n",
    "                         ncol=min(4, len(all_unique_labels)), \n",
    "                         fontsize=24, frameon=True, \n",
    "                         title='Label Color Mapping', title_fontsize=28)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308c559",
   "metadata": {},
   "source": [
    "Finally, let's do a quick examination of the height at all the points in the datasets so that we can see how this might affec the labels and therefore make decisions about how to model it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ab6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Define the datasets directory\n",
    "datasets_dir = Path(\"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets\")\n",
    "npz_files = sorted(datasets_dir.glob(\"*.npz\"))\n",
    "\n",
    "# Configuration\n",
    "max_points_for_height = 100000  # Points for height visualization\n",
    "point_size = 2  # Point size for scatter plots\n",
    "\n",
    "# First pass: Collect all unique labels across all datasets for consistent colors\n",
    "all_unique_labels = set()\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        data = np.load(npz_file)\n",
    "        labels = data.get('labels', None)\n",
    "        if labels is not None:\n",
    "            for sample_labels in labels:\n",
    "                all_unique_labels.update(np.unique(sample_labels))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Create consistent color map for all labels\n",
    "all_unique_labels = sorted(all_unique_labels)\n",
    "num_labels = len(all_unique_labels)\n",
    "# Use tab20 colormap which has 20 distinct colors, extend with Set3 if needed\n",
    "if num_labels <= 20:\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, num_labels))\n",
    "else:\n",
    "    # For more than 20 labels, use Set3 which has more colors\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, num_labels))\n",
    "consistent_color_map = {label: colors[i] for i, label in enumerate(all_unique_labels)}\n",
    "\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        # Load the .npz file\n",
    "        data = np.load(npz_file)\n",
    "        \n",
    "        # Load pointclouds and labels\n",
    "        pointclouds = data['pointclouds'] if 'pointclouds' in data else data.get('points', None)\n",
    "        labels = data.get('labels', None)\n",
    "        \n",
    "        if pointclouds is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the first sample\n",
    "        pc_full = pointclouds[0]\n",
    "        lbl_full = labels[0] if labels is not None else None\n",
    "        \n",
    "        # Sample points for visualization (100k points)\n",
    "        if len(pc_full) > max_points_for_height:\n",
    "            height_indices = np.random.choice(len(pc_full), max_points_for_height, replace=False)\n",
    "            pc_plot = pc_full[height_indices]\n",
    "            lbl_plot = lbl_full[height_indices] if lbl_full is not None else None\n",
    "            z_plot = pc_plot[:, 2]\n",
    "        else:\n",
    "            pc_plot = pc_full\n",
    "            lbl_plot = lbl_full\n",
    "            z_plot = pc_full[:, 2]\n",
    "        \n",
    "        # Calculate ranges\n",
    "        x_min, x_max = pc_plot[:, 0].min(), pc_plot[:, 0].max()\n",
    "        y_min, y_max = pc_plot[:, 1].min(), pc_plot[:, 1].max()\n",
    "        \n",
    "        # Create figure with two subplots side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "        \n",
    "        # ===== LEFT PLOT: Points colored by height (Z) =====\n",
    "        scatter = ax1.scatter(pc_plot[:, 0], pc_plot[:, 1], \n",
    "                            c=z_plot, s=point_size, alpha=0.6, \n",
    "                            cmap='terrain', edgecolors='none')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax1)\n",
    "        cbar.set_label('Height (Z)', fontsize=14)\n",
    "        \n",
    "        ax1.set_xlim(x_min, x_max)\n",
    "        ax1.set_ylim(y_min, y_max)\n",
    "        ax1.set_xlabel('X Coordinate', fontsize=12)\n",
    "        ax1.set_ylabel('Y Coordinate', fontsize=12)\n",
    "        ax1.set_title(f'{npz_file.name}\\nPoints Colored by Height (Z)', fontsize=14)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_aspect('auto')\n",
    "        \n",
    "        # ===== RIGHT PLOT: Points colored by labels =====\n",
    "        if lbl_plot is not None:\n",
    "            unique_labels = np.unique(lbl_plot)\n",
    "            \n",
    "            for label in unique_labels:\n",
    "                mask = lbl_plot == label\n",
    "                if np.any(mask):\n",
    "                    label_points = pc_plot[mask]\n",
    "                    # Use consistent color map\n",
    "                    color = consistent_color_map.get(label, 'gray')\n",
    "                    ax2.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                               c=[color], s=point_size, alpha=0.6, \n",
    "                               edgecolors='none')\n",
    "        else:\n",
    "            # If no labels, just plot points in gray\n",
    "            ax2.scatter(pc_plot[:, 0], pc_plot[:, 1], \n",
    "                       c='gray', s=point_size, alpha=0.6, edgecolors='none')\n",
    "            ax2.text(0.5, 0.5, 'No labels available', \n",
    "                    transform=ax2.transAxes, ha='center', va='center', fontsize=14)\n",
    "        \n",
    "        ax2.set_xlim(x_min, x_max)\n",
    "        ax2.set_ylim(y_min, y_max)\n",
    "        ax2.set_xlabel('X Coordinate', fontsize=12)\n",
    "        ax2.set_ylabel('Y Coordinate', fontsize=12)\n",
    "        ax2.set_title(f'{npz_file.name}\\nPoints Colored by Labels', fontsize=14)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_aspect('auto')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR processing {npz_file.name}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde2697",
   "metadata": {},
   "source": [
    "It looks like there is some noticeable correlation between heights and labels. As such, we can use pointnet++ as this implicitly accounts for changes in height.\n",
    "\n",
    "Next, let's see how we might patch the pointclouds in our data preprocessing for the model. Let's test how quickly the patches can be compiled. If it takes a long time, then we will stick to small number of patches and that too only for one dataset, and we can then use that just to demonstrate for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd284f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Define the datasets directory\n",
    "datasets_dir = Path(\"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets\")\n",
    "npz_files = sorted(datasets_dir.glob(\"*.npz\"))\n",
    "\n",
    "# Configuration\n",
    "num_seeds = 4000\n",
    "points_per_patch = 4096\n",
    "eps_factor = 0.01  # Fraction of point cloud extent for eps\n",
    "\n",
    "for npz_file in npz_files:\n",
    "    try:\n",
    "        print(f\"\\nProcessing: {npz_file.name}\")\n",
    "        \n",
    "        # Load the .npz file\n",
    "        data = np.load(npz_file)\n",
    "        pointclouds = data['pointclouds'] if 'pointclouds' in data else data.get('points', None)\n",
    "        labels = data.get('labels', None)\n",
    "        \n",
    "        if pointclouds is None:\n",
    "            continue\n",
    "        \n",
    "        # Get the first sample\n",
    "        points = pointclouds[0]\n",
    "        lbl = labels[0] if labels is not None else None\n",
    "        \n",
    "        print(f\"Total points: {len(points):,}\")\n",
    "        \n",
    "        # Estimate eps\n",
    "        point_ranges = points.max(axis=0) - points.min(axis=0)\n",
    "        eps = np.mean(point_ranges) * eps_factor\n",
    "        \n",
    "        # Randomly select seed points\n",
    "        if len(points) > num_seeds:\n",
    "            seed_indices = np.random.choice(len(points), num_seeds, replace=False)\n",
    "        else:\n",
    "            seed_indices = np.arange(len(points))\n",
    "            num_seeds = len(points)\n",
    "        \n",
    "        seed_points = points[seed_indices]\n",
    "        \n",
    "        # Extract patches for each seed\n",
    "        patches = []\n",
    "        patch_centers = []\n",
    "        patch_bboxes = []  # Store bounding boxes (x_min, x_max, y_min, y_max)\n",
    "        \n",
    "        for i, seed_point in enumerate(seed_points):\n",
    "            # Find points within eps distance\n",
    "            distances = np.linalg.norm(points - seed_point, axis=1)\n",
    "            nearby_mask = distances <= eps\n",
    "            nearby_points = points[nearby_mask]\n",
    "            \n",
    "            if len(nearby_points) < points_per_patch:\n",
    "                # Duplicate points if needed\n",
    "                num_needed = points_per_patch - len(nearby_points)\n",
    "                duplicate_indices = np.random.choice(len(nearby_points), num_needed, replace=True)\n",
    "                patch_points = np.vstack([nearby_points, nearby_points[duplicate_indices]])\n",
    "            elif len(nearby_points) > points_per_patch:\n",
    "                # Sample points if too many\n",
    "                sample_indices = np.random.choice(len(nearby_points), points_per_patch, replace=False)\n",
    "                patch_points = nearby_points[sample_indices]\n",
    "            else:\n",
    "                patch_points = nearby_points\n",
    "            \n",
    "            # Calculate bounding box\n",
    "            x_min, x_max = patch_points[:, 0].min(), patch_points[:, 0].max()\n",
    "            y_min, y_max = patch_points[:, 1].min(), patch_points[:, 1].max()\n",
    "            \n",
    "            patches.append(patch_points)\n",
    "            patch_centers.append(seed_point)\n",
    "            patch_bboxes.append((x_min, x_max, y_min, y_max))\n",
    "        \n",
    "        print(f\"Extracted {len(patches)} patches\")\n",
    "        \n",
    "        # Sample original point cloud for background visualization\n",
    "        max_bg_points = 50000\n",
    "        if len(points) > max_bg_points:\n",
    "            bg_indices = np.random.choice(len(points), max_bg_points, replace=False)\n",
    "            pc_bg = points[bg_indices]\n",
    "            lbl_bg = lbl[bg_indices] if lbl is not None else None\n",
    "        else:\n",
    "            pc_bg = points\n",
    "            lbl_bg = lbl\n",
    "        \n",
    "        # Calculate ranges\n",
    "        x_min_all, x_max_all = pc_bg[:, 0].min(), pc_bg[:, 0].max()\n",
    "        y_min_all, y_max_all = pc_bg[:, 1].min(), pc_bg[:, 1].max()\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        \n",
    "        # Plot background point cloud (colored by labels if available)\n",
    "        if lbl_bg is not None:\n",
    "            # Create consistent color map\n",
    "            unique_labels = sorted(np.unique(lbl_bg))\n",
    "            colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "            color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "            \n",
    "            for label in unique_labels:\n",
    "                mask = lbl_bg == label\n",
    "                if np.any(mask):\n",
    "                    label_points = pc_bg[mask]\n",
    "                    color = color_map[label]\n",
    "                    ax.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                             c=[color], s=0.3, alpha=0.2, edgecolors='none')\n",
    "        else:\n",
    "            ax.scatter(pc_bg[:, 0], pc_bg[:, 1], c='gray', s=0.3, alpha=0.2, edgecolors='none')\n",
    "        \n",
    "        # Plot seed points\n",
    "        ax.scatter(seed_points[:, 0], seed_points[:, 1], \n",
    "                  c='red', s=30, alpha=0.8, marker='x', linewidths=2, \n",
    "                  label=f'Seed Points ({num_seeds})', zorder=5)\n",
    "        \n",
    "        # Draw bounding boxes for ALL patches\n",
    "        for idx in range(len(patches)):\n",
    "            x_min, x_max, y_min, y_max = patch_bboxes[idx]\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            \n",
    "            # Draw bounding box\n",
    "            rect = Rectangle((x_min, y_min), width, height,\n",
    "                           linewidth=0.5, edgecolor='blue', facecolor='none', \n",
    "                           alpha=0.4, linestyle='--', zorder=3)\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        ax.set_xlim(x_min_all, x_max_all)\n",
    "        ax.set_ylim(y_min_all, y_max_all)\n",
    "        ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "        ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "        ax.set_title(f'{npz_file.name}\\nAll {len(patches)} Patch Bounding Boxes Overlaid on Labels', fontsize=14)\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('auto')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        bbox_areas = [(x_max - x_min) * (y_max - y_min) for x_min, x_max, y_min, y_max in patch_bboxes]\n",
    "        print(f\"Bounding box statistics:\")\n",
    "        print(f\"  Mean area: {np.mean(bbox_areas):.2f}\")\n",
    "        print(f\"  Min area: {np.min(bbox_areas):.2f}\")\n",
    "        print(f\"  Max area: {np.max(bbox_areas):.2f}\")\n",
    "        print(f\"  Std area: {np.std(bbox_areas):.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR processing {npz_file.name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11bb7cc",
   "metadata": {},
   "source": [
    "It takes a while, so below we will explore how to patch a small number with circles, we will use a similar method for our training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the ball query function from dataset.py for PyTorch PointNet++ training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from pointcloud_segmentation.dataset import extract_patches_ball_query_from_npz, BallQueryPatchDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Extract patches using ball query from the dataset\n",
    "npz_path = \"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets/odm_data_waterbury-roads_2.npz\"\n",
    "\n",
    "print(\"Extracting patches using ball query...\")\n",
    "patches, patch_centers, patch_labels = extract_patches_ball_query_from_npz(\n",
    "    npz_path=npz_path,\n",
    "    num_patches=50,  # Number of patches to extract\n",
    "    points_per_patch=4096,  # Exact number of points per patch\n",
    "    radius_percent=0.02,  # 2% of max(x_range, y_range)\n",
    "    sample_idx=0,\n",
    "    random_seed=42,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(patches)} patches\")\n",
    "print(f\"Patch shape: {patches.shape}\")  # Should be (num_patches, 4096, 3)\n",
    "print(f\"All patches have exactly 4096 points: ✓\")\n",
    "\n",
    "if patch_labels is not None:\n",
    "    print(f\"Patch labels shape: {patch_labels.shape}\")  # Should be (num_patches, 4096)\n",
    "    print(f\"Unique labels in patches: {np.unique(patch_labels)}\")\n",
    "else:\n",
    "    print(\"No labels available\")\n",
    "\n",
    "# Create a PyTorch Dataset from the patches\n",
    "dataset = BallQueryPatchDataset(patches, patch_labels)\n",
    "\n",
    "# Create a DataLoader for training\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Example: Get a batch\n",
    "batch_patches, batch_labels = next(iter(dataloader))\n",
    "print(f\"\\nBatch shape from DataLoader: {batch_patches.shape}\")  # Should be (batch_size, 4096, 3)\n",
    "if batch_labels is not None:\n",
    "    print(f\"Batch labels shape: {batch_labels.shape}\")  # Should be (batch_size, 4096)\n",
    "\n",
    "# Visualize a few patches\n",
    "num_patches_to_show = 5\n",
    "fig, axes = plt.subplots(1, num_patches_to_show, figsize=(20, 4))\n",
    "\n",
    "# Load original point cloud for background visualization\n",
    "data = np.load(npz_path)\n",
    "points = data['pointclouds'][0]\n",
    "labels = data['labels'][0] if 'labels' in data else None\n",
    "\n",
    "# Sample background points for context\n",
    "bg_sample_size = 10000\n",
    "bg_indices = np.random.choice(len(points), min(bg_sample_size, len(points)), replace=False)\n",
    "bg_points = points[bg_indices]\n",
    "\n",
    "# Calculate radius for visualization\n",
    "x_range = points[:, 0].max() - points[:, 0].min()\n",
    "y_range = points[:, 1].max() - points[:, 1].min()\n",
    "max_range = max(x_range, y_range)\n",
    "radius = max_range * 0.02\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx < len(patches):\n",
    "        patch = patches[idx]\n",
    "        center = patch_centers[idx]\n",
    "        \n",
    "        # Plot background points\n",
    "        ax.scatter(bg_points[:, 0], bg_points[:, 1], \n",
    "                  c='lightgray', s=0.5, alpha=0.3, edgecolors='none')\n",
    "        \n",
    "        # Plot patch points\n",
    "        ax.scatter(patch[:, 0], patch[:, 1], \n",
    "                  c='blue', s=2, alpha=0.6, edgecolors='none', label='Patch points')\n",
    "        \n",
    "        # Plot query center\n",
    "        ax.scatter(center[0], center[1], \n",
    "                  c='red', s=100, marker='x', linewidths=3, \n",
    "                  label='Query center', zorder=10)\n",
    "        \n",
    "        # Draw radius circle\n",
    "        circle = Circle((center[0], center[1]), radius, \n",
    "                       fill=False, edgecolor='red', linestyle='--', \n",
    "                       linewidth=2, alpha=0.7, label=f'Radius={radius:.1f}')\n",
    "        ax.add_patch(circle)\n",
    "        \n",
    "        # Set limits to show patch area\n",
    "        patch_x_range = patch[:, 0].max() - patch[:, 0].min()\n",
    "        patch_y_range = patch[:, 1].max() - patch[:, 1].min()\n",
    "        margin = max(patch_x_range, patch_y_range) * 0.2\n",
    "        \n",
    "        ax.set_xlim(center[0] - radius - margin, center[0] + radius + margin)\n",
    "        ax.set_ylim(center[1] - radius - margin, center[1] + radius + margin)\n",
    "        \n",
    "        ax.set_xlabel('X Coordinate', fontsize=10)\n",
    "        ax.set_ylabel('Y Coordinate', fontsize=10)\n",
    "        ax.set_title(f'Patch {idx+1}\\n({len(patch)} points)', fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall visualization showing all patches\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Plot all background points\n",
    "if labels is not None:\n",
    "    unique_labels = np.unique(labels[bg_indices])\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        mask = labels[bg_indices] == label\n",
    "        if np.any(mask):\n",
    "            label_points = bg_points[mask]\n",
    "            ax.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                      c=[color_map[label]], s=0.5, alpha=0.2, edgecolors='none')\n",
    "else:\n",
    "    ax.scatter(bg_points[:, 0], bg_points[:, 1], \n",
    "              c='lightgray', s=0.5, alpha=0.2, edgecolors='none')\n",
    "\n",
    "# Plot all query centers\n",
    "centers_array = np.array(patch_centers)\n",
    "ax.scatter(centers_array[:, 0], centers_array[:, 1], \n",
    "          c='red', s=50, marker='x', linewidths=2, \n",
    "          label=f'Query Centers ({len(patch_centers)})', zorder=10)\n",
    "\n",
    "# Draw radius circles for all patches\n",
    "for center in patch_centers:\n",
    "    circle = Circle((center[0], center[1]), radius, \n",
    "                   fill=False, edgecolor='blue', linestyle='--', \n",
    "                   linewidth=1, alpha=0.4)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "# Set limits\n",
    "x_min, x_max = points[:, 0].min(), points[:, 0].max()\n",
    "y_min, y_max = points[:, 1].min(), points[:, 1].max()\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "ax.set_title(f'Ball Query Patching: {len(patches)} Patches with Radius={radius:.2f}', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nPatch Statistics:\")\n",
    "print(f\"  All patches have exactly 4096 points: ✓\")\n",
    "print(f\"  Verified: {len(patches)} patches × 4096 points = {len(patches) * 4096:,} total patch points\")\n",
    "print(f\"\\nData format ready for PyTorch PointNet++ training:\")\n",
    "print(f\"  - Patches: shape {patches.shape} -> (num_patches, 4096, 3)\")\n",
    "print(f\"  - Labels: shape {patch_labels.shape if patch_labels is not None else 'None'} -> (num_patches, 4096)\")\n",
    "print(f\"  - Can be used with DataLoader for batch training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbde150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load patches for PointNet++ training\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Reload the module to get the latest functions (in case kernel was already running)\n",
    "if 'pointcloud_segmentation.dataset' in sys.modules:\n",
    "    importlib.reload(sys.modules['pointcloud_segmentation.dataset'])\n",
    "\n",
    "from pointcloud_segmentation.dataset import (\n",
    "    extract_and_save_patches_ball_query,\n",
    "    load_patches_ball_query,\n",
    "    save_patches_ball_query,\n",
    "    BallQueryPatchDataset\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Option 1: Extract and save patches in one step\n",
    "npz_path = \"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/datasets/odm_data_waterbury-roads_2.npz\"\n",
    "output_patches_path = \"/Users/hussainabass/Documents/pointcloud-segmentation-stub/data/ODMSemantic3D/patches_waterbury_roads_2.npz\"\n",
    "\n",
    "print(\"Extracting and saving patches...\")\n",
    "print(\"Note: Using 100 patches to avoid memory issues. Increase num_patches if needed.\")\n",
    "try:\n",
    "    extract_and_save_patches_ball_query(\n",
    "        npz_path=npz_path,\n",
    "        output_path=output_patches_path,\n",
    "        num_patches=100,  # Number of patches to extract (reduced to avoid memory issues)\n",
    "        points_per_patch=4096,  # Exact number of points per patch\n",
    "        radius_percent=0.02,  # 2% of max(x_range, y_range)\n",
    "        sample_idx=0,\n",
    "        random_seed=42,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error during extraction: {e}\")\n",
    "    print(\"Try reducing num_patches or using a smaller point cloud sample.\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Patches saved! Now loading them back...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Option 2: Load patches from saved file\n",
    "patches, patch_labels, patch_centers, metadata = load_patches_ball_query(output_patches_path)\n",
    "\n",
    "print(f\"\\nLoaded patches:\")\n",
    "print(f\"  - Shape: {patches.shape}\")\n",
    "print(f\"  - Labels shape: {patch_labels.shape if patch_labels is not None else 'None'}\")\n",
    "print(f\"  - Centers shape: {patch_centers.shape if patch_centers is not None else 'None'}\")\n",
    "if metadata:\n",
    "    print(f\"  - Metadata: {metadata}\")\n",
    "\n",
    "# Create PyTorch Dataset from loaded patches\n",
    "dataset = BallQueryPatchDataset(patches_path=output_patches_path)\n",
    "\n",
    "# Or create from arrays directly\n",
    "# dataset = BallQueryPatchDataset(patches=patches, patch_labels=patch_labels)\n",
    "\n",
    "# Create DataLoader for training\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Example: Get a batch\n",
    "batch_patches, batch_labels = next(iter(dataloader))\n",
    "print(f\"\\nBatch from DataLoader:\")\n",
    "print(f\"  - Patches shape: {batch_patches.shape}\")  # (batch_size, 4096, 3)\n",
    "print(f\"  - Labels shape: {batch_labels.shape if batch_labels is not None else 'None'}\")  # (batch_size, 4096)\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Visualizing patches...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load original point cloud for background\n",
    "data = np.load(npz_path)\n",
    "points = data['pointclouds'][0]\n",
    "labels = data['labels'][0] if 'labels' in data else None\n",
    "\n",
    "# Calculate radius for visualization\n",
    "x_range = points[:, 0].max() - points[:, 0].min()\n",
    "y_range = points[:, 1].max() - points[:, 1].min()\n",
    "max_range = max(x_range, y_range)\n",
    "radius = max_range * 0.02\n",
    "\n",
    "# Visualize a few patches\n",
    "num_patches_to_show = 5\n",
    "fig, axes = plt.subplots(1, num_patches_to_show, figsize=(20, 4))\n",
    "\n",
    "# Sample background points for context\n",
    "bg_sample_size = 10000\n",
    "bg_indices = np.random.choice(len(points), min(bg_sample_size, len(points)), replace=False)\n",
    "bg_points = points[bg_indices]\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx < len(patches):\n",
    "        patch = patches[idx]\n",
    "        center = patch_centers[idx] if patch_centers is not None else patch.mean(axis=0)\n",
    "        \n",
    "        # Plot background points\n",
    "        ax.scatter(bg_points[:, 0], bg_points[:, 1], \n",
    "                  c='lightgray', s=0.5, alpha=0.3, edgecolors='none')\n",
    "        \n",
    "        # Plot patch points\n",
    "        ax.scatter(patch[:, 0], patch[:, 1], \n",
    "                  c='blue', s=2, alpha=0.6, edgecolors='none', label='Patch points')\n",
    "        \n",
    "        # Plot query center\n",
    "        ax.scatter(center[0], center[1], \n",
    "                  c='red', s=100, marker='x', linewidths=3, \n",
    "                  label='Query center', zorder=10)\n",
    "        \n",
    "        # Draw radius circle\n",
    "        circle = Circle((center[0], center[1]), radius, \n",
    "                       fill=False, edgecolor='red', linestyle='--', \n",
    "                       linewidth=2, alpha=0.7, label=f'Radius={radius:.1f}')\n",
    "        ax.add_patch(circle)\n",
    "        \n",
    "        # Set limits to show patch area\n",
    "        patch_x_range = patch[:, 0].max() - patch[:, 0].min()\n",
    "        patch_y_range = patch[:, 1].max() - patch[:, 1].min()\n",
    "        margin = max(patch_x_range, patch_y_range) * 0.2\n",
    "        \n",
    "        ax.set_xlim(center[0] - radius - margin, center[0] + radius + margin)\n",
    "        ax.set_ylim(center[1] - radius - margin, center[1] + radius + margin)\n",
    "        \n",
    "        ax.set_xlabel('X Coordinate', fontsize=10)\n",
    "        ax.set_ylabel('Y Coordinate', fontsize=10)\n",
    "        ax.set_title(f'Patch {idx+1}\\n({len(patch)} points)', fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall visualization showing all patches\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Plot all background points\n",
    "if labels is not None:\n",
    "    unique_labels = np.unique(labels[bg_indices])\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        mask = labels[bg_indices] == label\n",
    "        if np.any(mask):\n",
    "            label_points = bg_points[mask]\n",
    "            ax.scatter(label_points[:, 0], label_points[:, 1], \n",
    "                      c=[color_map[label]], s=0.5, alpha=0.2, edgecolors='none')\n",
    "else:\n",
    "    ax.scatter(bg_points[:, 0], bg_points[:, 1], \n",
    "              c='lightgray', s=0.5, alpha=0.2, edgecolors='none')\n",
    "\n",
    "# Plot all query centers\n",
    "if patch_centers is not None:\n",
    "    centers_array = np.array(patch_centers)\n",
    "    ax.scatter(centers_array[:, 0], centers_array[:, 1], \n",
    "              c='red', s=50, marker='x', linewidths=2, \n",
    "              label=f'Query Centers ({len(patch_centers)})', zorder=10)\n",
    "    \n",
    "    # Draw radius circles for all patches\n",
    "    for center in patch_centers:\n",
    "        circle = Circle((center[0], center[1]), radius, \n",
    "                       fill=False, edgecolor='blue', linestyle='--', \n",
    "                       linewidth=1, alpha=0.4)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "# Set limits\n",
    "x_min, x_max = points[:, 0].min(), points[:, 0].max()\n",
    "y_min, y_max = points[:, 1].min(), points[:, 1].max()\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "ax.set_title(f'Ball Query Patching: {len(patches)} Patches with Radius={radius:.2f}', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready for PointNet++ training!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nYou can now use the DataLoader in your training loop:\")\n",
    "print(f\"  for batch_patches, batch_labels in dataloader:\")\n",
    "print(f\"      # batch_patches: (B, 4096, 3)\")\n",
    "print(f\"      # batch_labels: (B, 4096)\")\n",
    "print(f\"      # Train your model...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcloud-segmentation-stub-iuYnuDqC-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
